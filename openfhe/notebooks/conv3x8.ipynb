{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:25.046251Z",
     "start_time": "2024-06-24T23:39:25.028882Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "class lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lenet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.fc = nn.Linear(7200, 10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out ** 2\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = lenet()\n",
    "model.load_state_dict(torch.load(\"checkpoint/lenet_8/best.pth\").get(\"model\"))\n",
    "model.eval()\n",
    "os.makedirs(\"fastest\", exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Input",
   "id": "f166788dee94ae6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:25.404827Z",
     "start_time": "2024-06-24T23:39:25.399556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_slots = 8192\n",
    "\n",
    "def load_image(image_path, tensor_len):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image)\n",
    "    \n",
    "    image_flatten_tensor = torch.zeros((1, tensor_len))\n",
    "    image_flatten_tensor[0, :3 * 1024] = image_tensor.view((1, -1))\n",
    "    \n",
    "    return image_tensor.unsqueeze(0), image_flatten_tensor\n",
    "\n",
    "\n",
    "image_ori, image = load_image('./images/test.png', num_slots)\n",
    "image.shape"
   ],
   "id": "2d7af57207d23d8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conv1",
   "id": "5975834ee476a4bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert weight",
   "id": "87def60623557f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:26.489119Z",
     "start_time": "2024-06-24T23:39:26.259659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_flatten = model.conv1.weight.data.view(8, 3, -1)\n",
    "weights = torch.zeros((8, 9, 1024 * 3))\n",
    "bias = torch.zeros((8, 1024 * 3))\n",
    "\n",
    "for i in range(8):\n",
    "    bias[i, :] = model.conv1.bias.data[i]\n",
    "    for j in range(9):\n",
    "        for k in range(3):\n",
    "            weights[i, j, k * 1024 : k * 1024 + 1024] = weights_flatten[i, k, j]\n",
    "            \n",
    "            \n",
    "mask = torch.zeros((1, num_slots))\n",
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        mask[0, i * 32 + j] = 1\n",
    "        \n",
    "\n",
    "for i in range(8):\n",
    "    np.savetxt(f'fastest/conv1-ch{i}-bias.bin', bias[i, :], delimiter=',')\n",
    "    for j in range(9):\n",
    "        np.savetxt(f'fastest/conv1-ch{i}-k{j}.bin', weights[i, j, :], delimiter=',')\n",
    "\n",
    "np.savetxt('fastest/conv1-mask.bin', mask[0], delimiter=',')\n"
   ],
   "id": "293208ce168df51a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:26.493272Z",
     "start_time": "2024-06-24T23:39:26.490021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights.numpy().tofile('fastest/conv1-weights.bin')\n",
    "bias.numpy().tofile('fastest/conv1-bias.bin')"
   ],
   "id": "8533f724dc51148e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:27.185757Z",
     "start_time": "2024-06-24T23:39:27.182108Z"
    }
   },
   "cell_type": "code",
   "source": "bias.shape",
   "id": "bee2b3a2cbd875f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3072])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input rotate",
   "id": "7104ca741457178b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:27.467911Z",
     "start_time": "2024-06-24T23:39:27.464559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_rotations = []\n",
    "rolls = [0, 1, 2, 32, 33, 34, 64, 65, 66]\n",
    "for r in rolls:\n",
    "    image_rotations.append(torch.roll(image, -r))"
   ],
   "id": "8b9db1e0af8d666d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:27.650473Z",
     "start_time": "2024-06-24T23:39:27.644221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv_res = torch.zeros((1, num_slots))\n",
    "for i in range(8):\n",
    "    encoded_bias = torch.zeros((1, num_slots))\n",
    "    encoded_bias[0, :3072] = bias[i, :]\n",
    "    temp_res = torch.zeros((1, num_slots))\n",
    "    for j in range(9):\n",
    "        encoded_weights = torch.zeros((1, num_slots))\n",
    "        encoded_weights[0, :3072] = weights[i, j, :]\n",
    "        temp_res += image_rotations[j] * encoded_weights\n",
    "\n",
    "    temp_res = temp_res + torch.roll(temp_res, -1024) + torch.roll(temp_res, -2048) + encoded_bias\n",
    "    temp_res *= mask\n",
    "\n",
    "    if i == 0:\n",
    "        conv_res = temp_res\n",
    "    else:\n",
    "        conv_res += temp_res\n",
    "    conv_res = torch.roll(conv_res, -1024)\n",
    "    \n",
    "\n",
    "print(conv_res.shape)"
   ],
   "id": "cb02e0e78532effa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:39:28.351616Z",
     "start_time": "2024-06-24T23:39:28.345743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_correct(res, image_ori, model):\n",
    "    model_output = model.conv1(image_ori).squeeze()\n",
    "    res_reshape = torch.zeros_like(model_output)\n",
    "    for i in range(8):\n",
    "        for j in range(30):\n",
    "            res_reshape[i, j, :] = res[0, i * 1024 + 32 * j : i * 1024 + 32 * j + 30]\n",
    "            \n",
    "    print((res_reshape - model_output).abs().sum())\n",
    "    \n",
    "check_correct(conv_res, image_ori, model)"
   ],
   "id": "c5187d1227c0aadf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FC",
   "id": "7c7e842f7c26518f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert weight",
   "id": "b6f6deacbac2c17c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:08.075349Z",
     "start_time": "2024-06-24T23:40:08.047266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_flatten = model.fc.weight.data\n",
    "weights = torch.zeros((16, num_slots))\n",
    "bias = torch.zeros((1, num_slots))\n",
    "\n",
    "for i in range(10):\n",
    "    bias[0, i] = model.fc.bias.data[i]\n",
    "    for j in range(8):\n",
    "        for k in range(30):\n",
    "            weights[i, 1024 * j + 32 * k : 1024 * j + 32 * k + 30] = weights_flatten[i, 900 * j + 30 * k : 900 * j + 30 * k + 30]"
   ],
   "id": "d40cfc35e31a4531",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:08.357330Z",
     "start_time": "2024-06-24T23:40:08.354235Z"
    }
   },
   "cell_type": "code",
   "source": "weights.numpy().tofile('fastest/fc-weights.bin')",
   "id": "fe96bbe4ff5eb4a1",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:09.251525Z",
     "start_time": "2024-06-24T23:40:08.780690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_store = torch.zeros((16, 8192))\n",
    "for i in range(16):\n",
    "    for j in range(8192):\n",
    "            weights_store[i, j] = weights[j%16, (i+j)%8192]"
   ],
   "id": "91cde4124f0409cd",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:09.729829Z",
     "start_time": "2024-06-24T23:40:09.613747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(16):\n",
    "    np.savetxt(f'fastest/fc-c{i}.bin', weights_store[i, :], delimiter=',')\n",
    "\n",
    "np.savetxt('fastest/fc-bias.bin', bias[0], delimiter=',')"
   ],
   "id": "f14d53276ade301a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:09.763035Z",
     "start_time": "2024-06-24T23:40:09.758828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = conv_res ** 2\n",
    "\n",
    "final_res = torch.zeros((1, num_slots))\n",
    "\n",
    "for i in range(16):\n",
    "    final_res += weights_store[i] * torch.roll(feature[0], -i)\n",
    "\n",
    "rolls = [4096, 2048, 1024, 512, 256, 128, 64, 32, 16]\n",
    "\n",
    "for r in rolls:\n",
    "    final_res += torch.roll(final_res, -r)\n",
    "        \n",
    "final_res += bias"
   ],
   "id": "1c45c377aedec4f1",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:09.906067Z",
     "start_time": "2024-06-24T23:40:09.900863Z"
    }
   },
   "cell_type": "code",
   "source": "final_res[0,:10]",
   "id": "a266037316020d24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -4.8011,  -2.6713,   8.1740,  18.7194,   2.7581, -10.6273,  -1.4387,\n",
       "        -10.3061,  -5.7208,   5.1434])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:10.168548Z",
     "start_time": "2024-06-24T23:40:10.156636Z"
    }
   },
   "cell_type": "code",
   "source": "model(image_ori)",
   "id": "3abd6ee436bc6b33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.8011,  -2.6713,   8.1740,  18.7194,   2.7581, -10.6273,  -1.4387,\n",
       "         -10.3061,  -5.7208,   5.1434]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T23:40:37.067026Z",
     "start_time": "2024-06-24T23:40:37.063297Z"
    }
   },
   "cell_type": "code",
   "source": "weights.shape",
   "id": "859c200c92530567",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8192])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6bc77e2f027b3b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
