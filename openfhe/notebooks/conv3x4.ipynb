{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:14.994422Z",
     "start_time": "2024-06-06T22:55:13.783897Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "class lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lenet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.fc = nn.Linear(3600, 10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out ** 2\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = lenet()\n",
    "model.load_state_dict(torch.load(\"checkpoint/lenet/conv3x4/best.pth\").get(\"model\"))\n",
    "model.eval()\n",
    "os.makedirs(\"fastest\", exist_ok=True)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Input",
   "id": "f166788dee94ae6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:15.896465Z",
     "start_time": "2024-06-06T22:55:15.886211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_slots = 4096\n",
    "\n",
    "def load_image(image_path, tensor_len):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image)\n",
    "    \n",
    "    image_flatten_tensor = torch.zeros((1, tensor_len))\n",
    "    image_flatten_tensor[0, :3 * 1024] = image_tensor.view((1, -1))\n",
    "    \n",
    "    return image_tensor.unsqueeze(0), image_flatten_tensor\n",
    "\n",
    "\n",
    "image_ori, image = load_image('./images/test.png', num_slots)\n",
    "image.shape"
   ],
   "id": "2d7af57207d23d8a",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conv1",
   "id": "5975834ee476a4bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert weight",
   "id": "87def60623557f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:16.945340Z",
     "start_time": "2024-06-06T22:55:16.814080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_flatten = model.conv1.weight.data.view(4, 3, -1)\n",
    "weights = torch.zeros((4, 9, 1024 * 3))\n",
    "bias = torch.zeros((4, 1024 * 3))\n",
    "\n",
    "for i in range(4):\n",
    "    bias[i, :] = model.conv1.bias.data[i]\n",
    "    for j in range(9):\n",
    "        for k in range(3):\n",
    "            weights[i, j, k * 1024 : k * 1024 + 1024] = weights_flatten[i, k, j]\n",
    "            \n",
    "            \n",
    "mask = torch.zeros((1, num_slots))\n",
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        mask[0, i * 32 + j] = 1\n",
    "        \n",
    "\n",
    "for i in range(4):\n",
    "    np.savetxt(f'fastest/conv1-ch{i}-bias.bin', bias[i, :], delimiter=',')\n",
    "    for j in range(9):\n",
    "        np.savetxt(f'fastest/conv1-ch{i}-k{j}.bin', weights[i, j, :], delimiter=',')\n",
    "        \n",
    "np.savetxt('fastest/conv1-mask.bin', mask[0], delimiter=',')\n"
   ],
   "id": "293208ce168df51a",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input rotate",
   "id": "7104ca741457178b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:17.200611Z",
     "start_time": "2024-06-06T22:55:17.197111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_rotations = []\n",
    "rolls = [0, 1, 2, 32, 33, 34, 64, 65, 66]\n",
    "for r in rolls:\n",
    "    image_rotations.append(torch.roll(image, -r))"
   ],
   "id": "8b9db1e0af8d666d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:17.420880Z",
     "start_time": "2024-06-06T22:55:17.415449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv_res = torch.zeros((1, num_slots))\n",
    "for i in range(4):\n",
    "    encoded_bias = torch.zeros((1, num_slots))\n",
    "    encoded_bias[0, :3072] = bias[i, :]\n",
    "    temp_res = torch.zeros((1, num_slots))\n",
    "    for j in range(9):\n",
    "        encoded_weights = torch.zeros((1, num_slots))\n",
    "        encoded_weights[0, :3072] = weights[i, j, :]\n",
    "        temp_res += image_rotations[j] * encoded_weights\n",
    "\n",
    "    temp_res = temp_res + torch.roll(temp_res, -1024) + torch.roll(temp_res, -2048) + encoded_bias\n",
    "    temp_res *= mask\n",
    "\n",
    "    if i == 0:\n",
    "        conv_res = temp_res\n",
    "    else:\n",
    "        conv_res += temp_res\n",
    "    conv_res = torch.roll(conv_res, -1024)\n",
    "    \n",
    "conv_res = torch.roll(conv_res, -(num_slots - 1024 * 4))\n",
    "\n",
    "print(conv_res.shape)"
   ],
   "id": "cb02e0e78532effa",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:17.609207Z",
     "start_time": "2024-06-06T22:55:17.596922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_correct(res, image_ori, model):\n",
    "    model_output = model.conv1(image_ori).squeeze()\n",
    "    res_reshape = torch.zeros_like(model_output)\n",
    "    for i in range(4):\n",
    "        for j in range(30):\n",
    "            res_reshape[i, j, :] = res[0, i * 1024 + 32 * j : i * 1024 + 32 * j + 30]\n",
    "            \n",
    "    print((res_reshape - model_output).abs().sum())\n",
    "    \n",
    "check_correct(conv_res, image_ori, model)"
   ],
   "id": "c5187d1227c0aadf",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FC",
   "id": "7c7e842f7c26518f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert weight",
   "id": "b6f6deacbac2c17c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:18.126375Z",
     "start_time": "2024-06-06T22:55:18.100754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_flatten = model.fc.weight.data\n",
    "print(weights_flatten.shape)\n",
    "weights = torch.zeros((10, num_slots))\n",
    "bias = torch.zeros((1, num_slots))\n",
    "\n",
    "for i in range(10):\n",
    "    bias[0, i] = model.fc.bias.data[i]\n",
    "    for j in range(4):\n",
    "        for k in range(30):\n",
    "            weights[i, 1024 * j + 32 * k : 1024 * j + 32 * k + 30] = weights_flatten[i, 900 * j + 30 * k : 900 * j + 30 * k + 30]\n",
    "            \n",
    "mask = torch.zeros((1, num_slots))\n",
    "mask[0, 0] = 1"
   ],
   "id": "d40cfc35e31a4531",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:18.367513Z",
     "start_time": "2024-06-06T22:55:18.314863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    np.savetxt(f'fastest/fc-c{i}.bin', weights[i, :], delimiter=',')\n",
    "\n",
    "np.savetxt('fastest/fc-mask.bin', mask[0], delimiter=',')\n",
    "np.savetxt('fastest/fc-bias.bin', bias[0], delimiter=',')\n"
   ],
   "id": "f14d53276ade301a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:18.532741Z",
     "start_time": "2024-06-06T22:55:18.527527Z"
    }
   },
   "cell_type": "code",
   "source": "weights_flatten.shape",
   "id": "14f652a2401b11e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:18.669940Z",
     "start_time": "2024-06-06T22:55:18.665637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = conv_res ** 2\n",
    "\n",
    "final_res = torch.zeros((1, num_slots))\n",
    "\n",
    "rolls = [2048, 1024, 512, 256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "\n",
    "for i in range(10):\n",
    "    current = feature * weights[i]\n",
    "    for r in rolls:\n",
    "        current += torch.roll(current, -r)\n",
    "    \n",
    "    if i == 0:\n",
    "        final_res = current * mask\n",
    "    else:\n",
    "        final_res = final_res + torch.roll(current * mask,  i)\n",
    "        \n",
    "final_res += bias"
   ],
   "id": "1c45c377aedec4f1",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:18.867147Z",
     "start_time": "2024-06-06T22:55:18.863342Z"
    }
   },
   "cell_type": "code",
   "source": "final_res.shape",
   "id": "a266037316020d24",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:19.024722Z",
     "start_time": "2024-06-06T22:55:19.009934Z"
    }
   },
   "cell_type": "code",
   "source": "model(image_ori)",
   "id": "3abd6ee436bc6b33",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T22:55:19.361118Z",
     "start_time": "2024-06-06T22:55:19.354445Z"
    }
   },
   "cell_type": "code",
   "source": "final_res[0,:10]",
   "id": "1c04fac6a9b7a404",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T00:35:57.572937Z",
     "start_time": "2024-06-05T00:35:57.570928Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9322c0bbb3f8c472",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "ecdd589b5fa4ab8a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
